CPU 

1. CPU: 입력장치로부터 자료를 받아 연산하고 그 결과를 출력장치로 보내는 일련의 과정을 제어 및조정하는 핵심장치로 보내는 일련의 과정을 제어 및 조정하는 핵심장치

2. CPU의 구성요소
   1) ALU(연상장치)
      각종 산술연산들과 논리연산들을 수행하는 회로
      산술연산: +,-,*,/
      논리연산: AND, OR, NOT, XOR

   2) Register(레지스터)
      CPU 내부의 소규모 데이터나 중간 결과를 일시적을 기억해 두는 고소그이 전용 영역
      컴퓨터 기억장치 중 Access 속도가 가장 빠름

   3) Control Unit(제어장치)
      프로그램 코드를 해석하고, 그것을 실행하기 위한 제어 신호들을 발생시킴

   4) 내부 CPU 버스 
      ALU와 레지스터 간의 데이터 이동을 위한 경로

4. 내부 레지스터의 종류
   1) PC(Program Counter)
      다음에 수행할 명령어가 저장된 주기억장치의 번지를 지정

   2) MAR(Memory Address Register)
      주기억장치에 접근하기 위한 주기억장치의 번저를 기억

   3) MBR(Memory Buffer Register)
      주기억장치에 입/출력할 자료를 기억하는 레지스터

   4) IR(Instruction Register)
      주기억장치에서 인출한 명령코드를 기억하는 레지스터

버스 시스템(Bus System)

1. 버스: 시스템에 많은 장치를 공유하여 데이터, 주소, 제어 정보를 전달하는 전송 라인

2. 버스 종류
   1) 데이터 버스
      시스템 컴포넌트 간 처리 데이터를 전송하기 위한 용도

   2) 주소 버스
      기억장소의 위치 또는 장치 식별을 지정하기 위한 라인
      라인의 비트 수에 따라 접속될 수 있는 장치의 용량이 결정됨

   3) 제어 버스
      CPU와 기억장치 또는 I/O 장치 사이의 제어 신호를 전송하는 라인

CPU의 명령 실행 주기(Instruction Cycle)

1. CPU의 명령어 처리: 하나의 명령어 실행이 끝난 후, 다음 명령어의 수행이 시작되어 끝날때까지 걸리는 시간

2. Instruction Cycle
   1) 인출(Instruction Fetch)
      인출단계는 메모리에서 데이터를 로드하여 CPU에 있는 레지스터에 적재하는 과정

   2) 간접(Indirect)
      메모리를 참조할 때 간접주소 방식을 사용하는 경우에 실행
      간접주소란 CPU가 메모리를 참조했을 때 데이터가 존재하는 것이 아니라 메모리에 주소가 존재하여 메모리내에서 한 번 더 조회해서 데이터를 얻는 것

   3) 실행(Execution)
      명령과 데이터로 CPU가 산술 및 논리연산을 수행하는 것

   4) 인터럽트(Interrupt)
      컴퓨터 작동 중 예기치 않은 문제가 발생한 경우라도 업무 처리가 계속될 수 있도록 하는 컴퓨터 운영체제의 한 긴으으로, 크게 하드웨어 인터럽트와 소트프웨어 인터럽트로 나뉨
      SVC 하드웨어 인터럽트- 기계착오 인터럽트, 외부 인터럽트, 입출력 인터럽트, 프로그램 검사 인터럽트
      소프트웨어 인터럽트 - CPU 내부에서 자신이 실행한 명령이나 CPU의 명령 실행에 관련된 모듈이 변화하는 경우 발생

메모리 시스템

1. 기억장치 계층구조
  1) 메모리 계층구조의 이유
     액세스 속도가 높아질수록 비트당 가격도 높아짐
     용량이 커질수록 비트당 가격이 낮아짐
     용량이 커질수록 액세스 속도가 낮아짐

   2) 기억장치 계층구조
      보조기억장치 -> 주기억장치 -> 캐시 -> 레지스터

2. 캐시 메모리
   1) 캐시 메모리: CPU와 주기억장치의 속도 차이를 극복하기 위해 CPU와 주기억장치 사이에 존재하는 고속의 버퍼 메모리 

   2) 캐시 메모리 사상 방식
      i 직접사상
         Main Memoery를 여러 구역으로 분할하여 Cache 슬록과 매핑
         장점: 매핑 절차가 단순하고 신속하게 처리
         단점: 높은 캐시 미스율

      ii 연관사상
         Main Memory의 각 블록이 Cache의 어느 슬록이든 적재 가능
         장점: 지역성 높은 접근 시 캐시 적중률 높음
         단점: 구현 하드웨어가 복잡하여 구현 비용 상승

      iii 집합 연관사상
          직접사상/연관사상 절충 방식으로 캐시와 메모리가 M 대 1로 대응
          장점: 직접사상과 연관사상의 장점 수용
          단점: 캐시 Fin/Fout 발생 증가, 구현 비용이 많이 듬

  3. 캐시 메모리 관리 방식
     1) 캐시 메모리 인출 방식
        Demand Fetch: 필요 시 캐시를 인출하는 방식
        Pre-Fetch: 예상되는 블록을 미리 패치 해 두는 방식

     2) 캐시 메모리 교체 알고리즘의 종류
        - Random
          교체될 Page를 임의 선정
          Overhead가 적음

        - FIFO
          캐시 내에 오래 있었던 Page 교체
          자주 사용되는 Page가 교체될 우려

        - LFU
          사용 횟수가 가장 적은 Page 교체
          최근 적재된 Page가 교체될 우려

        - LRU
          가장 오랫동안 사용되지 않는 Page 교체
          Time stamping에 의한 overhead 존재

        - Optimal 
          향후 가장 참조되지 않을 Page 교체
          실현 불가능

        - NUR
          참조 비트와 수정 비트로 미사용 Page 교체
          최근 사용되지 않은 페이지 교체

        - SCR
          최초 참조 비트 1로 셋, 1인 경우 0으로 셋, 0인 경우 교체
          기회를 한 번 더 줌

    3) 페이지 교체 관리 시 문제점
       i Page Fault 발생 
         기억장치에 적재되지 않은 Page를 사용하려 할 때 Page Fault 발생

       ii Demand Paging
          요구될 때에만 Process가 Page를 적재하는 방식

       iii Threashing 발생
           Pagㄷ 부재가 너무 빈번하게 발생하여 CPU가 Process 수행보다 Page 교체에 더 많은 시간을 소요하는 비정상적인 현상

캐시 메모리 일관성 유지 방식


